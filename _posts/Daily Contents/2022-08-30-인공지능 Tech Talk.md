---
title: "[Daily Contents] 인공지능 Tech Talk"
categories:
  - Daily Contents
tags:
  - Daily Contents
  # -
toc: true
toc_sticky: true
toc_label: "인공지능 Tech Talk"
toc_icon: "bookmark"
---

<br>

## AI란?

**감지하고 있는 것에 반응하여, 환경을 인지하고, 생각하며, 배우고, 행동을 취할 수 있는 컴퓨터 시스템**

- Sense : their environment
- Think
- Learn
- Take Action

Automated intelligence : 수동적으로 진행한 업무 또는 인지 등의 자동화 <br>
Assisted intelligence : 인간이 더 빠르고 더 정확하게 업무를 수행하는 것을 돕는 역할 <br>
Augmented intelligence : 더 나은 의사결정에 도움을 주는 역할 <br>
Autonomous intelligence : 인간의 개입이 없는 의사 결정 프로세스의 자동화 <br>

```
학습 자료 : Big Data
학습 방법 : Machine Learning Technique
자동화/관리 : Automation & Management
```

### 어린 아이에게 한글을 가르치는 과정

#### 학습 자료 : 교재

- 정제되지 않은 데이터 >> 데이터 정제 >> 학습 데이터
- 인공지능 관점
  - 무의미한 데이터의 제거(Noise 제거) ex) 텍스트 내의 특수 기호, 광고 글, 무의미한 링크 등
  - 학습하기 위한 형태로의 변경 ex) 문서 내에서 문장 단위 분리, 데이터 포맷 일원화 등
  - 학습을 위한 Labeling 작업 ex) 고양이 사진, 개 사진, Sentiment문장, 그렇지 않은 문장 등

#### 학습 방법 : 교육법

- 교재에 맞는 교육법, 교육법에 맞는 교재
- 인공지능 관점
  - 영상 인식 & 분류 방법 : Convolution Neural Network, Capsule Network
  - Sentence 분류 방법 : Recurrent Neural Network, Convolution Neural Network with Word2Vec
  - 시계열 예측 방법 : Long Short-Term Neural Network

#### 자동화/관리 : 스스로 공부하는 습관

- 인공지능 관점
  - 학습 데이터 수동/자동 생성 : 데이터 전처리&정제
  - 학습 스케쥴링에 의한 자동 학습 : 데이터 추가 학습
  - 학습 모델 LifeCycle 관리 : 모델 배포 및 업그레이드

### 사람처럼 행동하도록 만들어진 장치 또는 소프트웨어

**인공지능에 대한 기대**

- 시간 효율성 : 사람보다 훨씬 빠르게 분석해서 결과를 도출, 대량의 데이터를 핸들링
- 비용 효율성 : 여러 사람이 해야 할 일을 기계가 처리, 24시간 365일 업무를 수행
- 객관성 유지 : 항상 같은 기준으로 분석/판단을 수행
- 진화 : 인간이 미처 발견하지 못한 데이터의 특성 인지

### 과거와 현재

- 1956
  - 인공지능 초기 : 엘런 튜링(튜링 테스트와 튜링머신 고안)
- 1960~1980
  - 1차 인공지능 붐 : 규칙 기반 자동 판정 프로그램, 추론엔진, 전문가 시스템의 등장
- 1980~2000
  - 2차 인공지능 붐 : 연산속도의 비약적 발전, 무어의 법칙의 현실화, 퍼셉트론의 다중화, 오차역전파법 개발(신경망 연구의 발전)
- 2000~2010
  - 기술의 발전기 : 통계기반 머신러닝 분산처리 기술, 딥러닝 시대의 도래(AutoEncoder, Deep Nueral Network)
- 2010~
  - 3차 인공지능 붐 : 딥러닝 기반 이미지 인식 성능 향상(AlexNet, Convolutional Neural Network)

### AI에 대한 Question

#### 가르치는 관점

- 아이가 학습하는 과정을 이해 : 사고하고 배우는 과정의 원래를 이해, 아이가 학습한 결과를 설명하는 원인 요소를 파악
- 적은 양의 교재 & 짧은 학습 시간
- 학습 효율을 높일 수 있는 효과적인 방법 : 성능 개선
- 개발한 학습법을 다른 영역을 가르칠 때 재활용 또는 효과적으로 적용할 수 있는 영역
- 선생님의 개입을 최소화하는 학습
- 학습법을 개발하기 위한 쉬운 툴
- 스스로 학습하여 발전(진화)할 수 있는 방법

#### 인공지능 관점

- 학습하는 원리와 과정 이해
  - Deep Learning은 학습 과정을 알 수 없음
  - Deep Learning Model의 성능이 좋은 이유와 원인을 증명할 수 없음
- 적은 학습 데이터, 짧은 학습 시간
  - 많은 양의 학습 데이터를 생성하는 시간과 인력이 필요
  - 많은 양의 학습을 진행하려면 많은 Computing Power & Resource가 필요
- 효과적인 학습 모델(학습 효율)
  - Deep Learning의 성능을 개선할 새로운 개념 및 신경망 이론이 필요
- 학습법의 재활용
  - 한 영역에서 개발한 인공지능 모델을 다른 영역에 적용하여 개발 효율을 높임
  - 효과적으로 적용할 수 있는 분야 또는 영역
- 전문가의 개입 최소화
  - 인간의 개입을 최소화하는 인공지능 모델 필요
- 학습법을 개발하기 위한 쉬운 틀
  - 인공지능 모델을 개발하기 위한 쉽고 편리한 소프트웨어 개발 틀 및 개념
- 스스로 학습
  - AI Tool의 민주화
  - AI 모델 개발 과정을 Programming 지식 없이도 수행할 수 있도록 하는 Platform이 필요
  - 학습 자동화 툴

### CNN의 기본 구성

```
Convolution Filer : 다양한 특징을 생성
Pooling : 특징 중 강한 특징들을 살리면서 차원을 축소
Relu : Activation Function - 불필요한 Feature를 제거하는 역할
Fully Connected : Classification 결정 이전에 Feature들을 재조합하는 연산
Softmax : 확률 값을 내어 보내어 다양한 값을 분류하기 위함
```

### BERT(AI 관련기술, 구글의 베이스 모델)

#### BERT의 설계 의도

**Pre-training**

- MLM(Masked Language Model)
  - MaskedToken에 대한 정답을 찾는 Task
- NSP(Next Sentence Classfication)
  - 두 개의 문장이 연속된 문장인지 판별하는 Taskv

**Fine-Tuning**

- Sentence Pair Classification Tasks
- Single Sentence Classification Tasks
- Question Answering Tasks
- Single Sentence Tagging Tasks

#### BERT 모델 Architecture

- Multi-layer bidirectional Transformer encoder
- BERTbase
- BERTlarge

#### Input/Output Representation

**Pre-training**

- CLS : sequence의 시작을 나타내는 첫번째 토큰
- SEP : 두 sentence를 구별하는 토큰
- C : CLS 토큰에 해당하는 마지막 hidden vector
- $T_N$ : N번째 토큰에 해당하는 마지막 hidden vector
- Token embedding : WordPiece embeddings(3만 토큰 사전)
- Segment embedding : 문장의 앞뒤를 구분
- Position embedding : 토큰의 위치 정보를 포함

#### AI 기반 외환거래 자동 점검 솔루션 구축 사례에서의 개체명 인식 엔진의 활용

#### 개체명 인식 모델의 학습 / 적용 / 검증을 위한 절차

- **수행 절차**

  - 로그 데이터 전처리 >> 데이터 Annotation >> 개체명 인식 모델 학습 >> 정보 추출

- **단계별 수행 업무**
  - 개체명 인식 수행을 위한 로그 데이터 전처리 수행
  - 인공지능 모델 학습을 위해 개체명에 해당하는 단어의 Category와 위치 정보 생성
  - Category와 위치 정보를 활용한 로그 데이터를 이용하여 개체명 인식 모델 학습 수행
  - 문자열 로그 데이터의 개체명 인식 결과 추출
- **성능 측정**
  - Category 정확도 : 추출한 개체명의 카테고리 정보가 원본 데이터의 카테고리 정보와 일치하는 항목 수 확인
  - 위치 추출 정확도 : 추출한 개체명의 위치 정보가 원본 데이터의 위치 정보와 일치하는 항목 수 확인

#### 개체명 인식 모델 성능 검증 결과

- 개체명 인식 모델 성능 : F1 score 93.15
- 개체명 인식 모델 카테고리 별 성능 : 평균 성능 93.07%
